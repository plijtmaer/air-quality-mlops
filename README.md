# ğŸŒ¬ï¸ Air Quality MLOps

Proyecto de MLOps end-to-end para clasificaciÃ³n de calidad del aire, desarrollado como trabajo final de posgrado.

## ğŸ“‹ DescripciÃ³n

Pipeline completo de Machine Learning Operations que:
1. **Ingesta** datos de calidad del aire desde Open-Meteo API (Airflow)
2. **Transforma** los datos crudos usando PySpark
3. **Versiona** datos con DVC + DagsHub
4. **Gestiona features** con Feast Feature Store
5. **Entrena** modelos con PyCaret + Optuna + MLflow
6. **Sirve** predicciones via FastAPI (prÃ³ximamente)
7. **Monitorea** data drift con Evidently (prÃ³ximamente)

## ğŸ› ï¸ Stack TecnolÃ³gico

| Componente | TecnologÃ­a | Estado |
|------------|------------|--------|
| OrquestaciÃ³n | Apache Airflow 2.10 | âœ… |
| Contenedores | Docker & Docker Compose | âœ… |
| TransformaciÃ³n | PySpark (local mode) | âœ… |
| Versionado de Datos | DVC + DagsHub | âœ… |
| Feature Store | Feast | âœ… |
| AutoML | PyCaret | âœ… |
| Hyperparameter Tuning | Optuna | âœ… |
| Experiment Tracking | MLflow (DagsHub) | âœ… |
| API | FastAPI | â³ |
| Monitoreo | Evidently | â³ |
| IaC | Terraform | â³ |
| Kubernetes | Kind (local) | â³ |

## ğŸ“ Estructura del Proyecto

```
air-quality-mlops/
â”œâ”€â”€ airflow/                          # Apache Airflow
â”‚   â”œâ”€â”€ dags/                         # Definiciones de DAGs
â”‚   â”‚   â”œâ”€â”€ hello_airflow.py          # DAG de prueba
â”‚   â”‚   â”œâ”€â”€ ingest_air_quality.py     # Ingesta desde Open-Meteo
â”‚   â”‚   â””â”€â”€ transform_air_quality.py  # TransformaciÃ³n PySpark
â”‚   â”œâ”€â”€ docker-compose.yaml           # Servicios Docker
â”‚   â”œâ”€â”€ Dockerfile                    # Imagen custom (Java+PySpark)
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ src/                              # CÃ³digo fuente Python
â”‚   â”œâ”€â”€ ingestion/                    # MÃ³dulo de ingesta
â”‚   â”‚   â””â”€â”€ open_meteo_client.py      # Cliente Open-Meteo API
â”‚   â”œâ”€â”€ transform/                    # MÃ³dulo de transformaciÃ³n
â”‚   â”‚   â””â”€â”€ air_quality_transform.py  # Pipeline PySpark
â”‚   â”œâ”€â”€ training/                     # MÃ³dulo de entrenamiento
â”‚   â”‚   â””â”€â”€ train.py                  # PyCaret + Optuna + MLflow
â”‚   â”œâ”€â”€ inference/                    # MÃ³dulo de inferencia (prÃ³ximamente)
â”‚   â””â”€â”€ monitoring/                   # MÃ³dulo de monitoreo (prÃ³ximamente)
â”‚
â”œâ”€â”€ feature_store/                    # Feast Feature Store
â”‚   â””â”€â”€ air_quality_features/
â”‚       â””â”€â”€ feature_repo/
â”‚           â”œâ”€â”€ air_quality_features.py  # DefiniciÃ³n de features
â”‚           â””â”€â”€ feature_store.yaml       # ConfiguraciÃ³n
â”‚
â”œâ”€â”€ data/                             # Datos (versionados con DVC)
â”‚   â”œâ”€â”€ raw/                          # JSON crudos de la API
â”‚   â””â”€â”€ curated/                      # Parquet procesados
â”‚
â”œâ”€â”€ models/                           # Modelos entrenados
â”‚   â””â”€â”€ air_quality_*_tuned.pkl       # Modelo PyCaret
â”‚
â”œâ”€â”€ .dvc/                             # ConfiguraciÃ³n DVC
â”œâ”€â”€ .venv/                            # Virtual environment
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .gitattributes
â”œâ”€â”€ data/raw.dvc                      # Puntero DVC a datos raw
â”œâ”€â”€ data/curated.dvc                  # Puntero DVC a datos curated
â””â”€â”€ README.md
```

## ğŸš€ Inicio RÃ¡pido

### Requisitos Previos

- Python 3.11+
- Docker Desktop
- Git
- ~6GB de espacio en disco

### 1. Clonar y Configurar Entorno

```bash
git clone https://github.com/plijtmaer/air-quality-mlops.git
cd air-quality-mlops

# Crear virtual environment con uv (recomendado)
uv venv .venv --python 3.11 --seed
source .venv/Scripts/activate  # Windows Git Bash
# o
.venv\Scripts\activate         # Windows PowerShell

# Instalar dependencias
uv pip install dvc dagshub mlflow feast pycaret optuna
```

### 2. Descargar Datos (DVC)

```bash
# Configurar credenciales DVC (solo primera vez)
dvc remote modify origin --local auth basic
dvc remote modify origin --local user TU_USUARIO_DAGSHUB
dvc remote modify origin --local password TU_TOKEN_DAGSHUB

# Descargar datos
dvc pull
```

### 3. Ejecutar Training

```bash
python -m src.training.train

# Con parÃ¡metros personalizados
python -m src.training.train --metric F1 --min-f1 0.7 --tune-trials 30
```

### 4. Levantar Airflow (opcional)

```bash
cd airflow
docker compose build
docker compose up -d
# UI: http://localhost:8080 (airflow/airflow)
```

## ğŸ“Š Pipeline de Datos

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Open-Meteo    â”‚â”€â”€â”€â”€â–¶â”‚   data/raw/     â”‚â”€â”€â”€â”€â–¶â”‚  data/curated/  â”‚
â”‚      API        â”‚     â”‚   *.json        â”‚     â”‚   *.parquet     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                       â”‚                       â”‚
   Airflow DAG             DVC tracked            PySpark ETL
   (@hourly)                                    + clasificaciÃ³n
```

## ğŸ¤– Pipeline de Training

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  data/curated/  â”‚â”€â”€â”€â”€â–¶â”‚     PyCaret     â”‚â”€â”€â”€â”€â–¶â”‚     Optuna      â”‚
â”‚   *.parquet     â”‚     â”‚ compare_models  â”‚     â”‚   tune_model    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚                       â”‚
                               â–¼                       â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚     MLflow      â”‚     â”‚     models/     â”‚
                        â”‚    (DagsHub)    â”‚     â”‚   *.pkl         â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Resultados del Ãšltimo Training

| MÃ©trica | Valor |
|---------|-------|
| **Mejor modelo** | Decision Tree Classifier |
| **F1 Score** | 0.9886 (98.86%) |
| **AUC** | 0.95 (95%) |
| **Accuracy** | 0.9923 (99.23%) |

Ver experimentos: https://dagshub.com/plijtmaer/air-quality-mlops.mlflow

## ğŸ½ï¸ Feast Feature Store

Features definidas para calidad del aire:

| Feature | Tipo | DescripciÃ³n |
|---------|------|-------------|
| `pm2_5` | Float | PM2.5 (Î¼g/mÂ³) |
| `pm10` | Float | PM10 (Î¼g/mÂ³) |
| `carbon_monoxide` | Float | CO (Î¼g/mÂ³) |
| `nitrogen_dioxide` | Float | NO2 (Î¼g/mÂ³) |
| `sulphur_dioxide` | Float | SO2 (Î¼g/mÂ³) |
| `ozone` | Float | O3 (Î¼g/mÂ³) |
| `us_aqi` | Int | US Air Quality Index |
| `european_aqi` | Int | European AQI |
| `air_quality_label` | String | good/moderate/unhealthy |

### Usar Feast

```bash
cd feature_store/air_quality_features/feature_repo

# Aplicar definiciones
feast apply

# Materializar features
feast materialize-incremental $(date -u +"%Y-%m-%dT%H:%M:%S")
```

## ğŸ“ˆ ClasificaciÃ³n de Calidad del Aire

Basada en EPA AQI para PM2.5:

| Etiqueta | PM2.5 (Î¼g/mÂ³) | DescripciÃ³n |
|----------|---------------|-------------|
| `good` | < 12 | Buena calidad |
| `moderate` | 12 - 35.4 | Calidad moderada |
| `unhealthy` | â‰¥ 35.4 | No saludable |

## ğŸ”— Enlaces

- **DagsHub Repo**: https://dagshub.com/plijtmaer/air-quality-mlops
- **MLflow Experiments**: https://dagshub.com/plijtmaer/air-quality-mlops.mlflow
- **Open-Meteo API**: https://open-meteo.com/en/docs/air-quality-api

## ğŸ“ PrÃ³ximos Pasos

- [ ] **FastAPI**: API REST para inferencia (`src/inference/`)
- [ ] **Evidently**: Monitoreo de data drift
- [ ] **Docker**: Containerizar la aplicaciÃ³n completa
- [ ] **Terraform**: Infraestructura como cÃ³digo
- [ ] **Kind**: Deployment en Kubernetes local
- [ ] **GitHub Actions**: CI/CD

## ğŸ› ï¸ Comandos Ãštiles

```bash
# Training
python -m src.training.train

# DVC
dvc pull                    # Descargar datos
dvc push                    # Subir datos
dvc status                  # Ver estado

# Feast
cd feature_store/air_quality_features/feature_repo
feast apply                 # Aplicar cambios
feast materialize-incremental "2025-12-05T00:00:00"

# Airflow
cd airflow
docker compose up -d        # Levantar
docker compose down         # Detener
docker compose logs -f      # Ver logs
```

## ğŸ‘¤ Autor

Proyecto desarrollado por **Paul Lijtmaer** como trabajo final de posgrado en MLOps.

## ğŸ“„ Licencia

Este proyecto es de uso acadÃ©mico.
