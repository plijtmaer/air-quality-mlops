# ğŸŒ¬ï¸ Air Quality MLOps

Proyecto de MLOps end-to-end para clasificaciÃ³n de calidad del aire, desarrollado como trabajo final de posgrado.

## ğŸ“‹ DescripciÃ³n

Pipeline completo de Machine Learning Operations que:
1. **Ingesta** datos de calidad del aire desde Open-Meteo API
2. **Transforma** los datos crudos usando PySpark
3. **Entrena** modelos de clasificaciÃ³n (prÃ³ximamente)
4. **Despliega** una API de inferencia (prÃ³ximamente)
5. **Monitorea** el drift de datos (prÃ³ximamente)

## ğŸ› ï¸ Stack TecnolÃ³gico

| Componente | TecnologÃ­a |
|------------|------------|
| OrquestaciÃ³n | Apache Airflow 2.10 |
| Contenedores | Docker & Docker Compose |
| TransformaciÃ³n | PySpark (local mode) |
| Entrenamiento | PyCaret + Optuna (prÃ³ximamente) |
| Tracking ML | MLflow (prÃ³ximamente) |
| API | FastAPI (prÃ³ximamente) |
| Monitoreo | Evidently (prÃ³ximamente) |
| CI/CD | GitHub Actions (prÃ³ximamente) |

## ğŸ“ Estructura del Proyecto

```
air-quality-mlops/
â”œâ”€â”€ airflow/                    # ConfiguraciÃ³n de Apache Airflow
â”‚   â”œâ”€â”€ dags/                   # Definiciones de DAGs
â”‚   â”‚   â”œâ”€â”€ hello_airflow.py    # DAG de prueba
â”‚   â”‚   â”œâ”€â”€ ingest_air_quality.py
â”‚   â”‚   â””â”€â”€ transform_air_quality.py
â”‚   â”œâ”€â”€ logs/                   # Logs de ejecuciÃ³n (gitignore)
â”‚   â”œâ”€â”€ plugins/                # Plugins personalizados
â”‚   â”œâ”€â”€ docker-compose.yaml     # Servicios Docker
â”‚   â”œâ”€â”€ Dockerfile              # Imagen custom con Java+PySpark
â”‚   â”œâ”€â”€ .env                    # Variables de entorno
â”‚   â””â”€â”€ README.md               # DocumentaciÃ³n de Airflow
â”‚
â”œâ”€â”€ src/                        # CÃ³digo fuente Python
â”‚   â”œâ”€â”€ ingestion/              # MÃ³dulo de ingesta
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ open_meteo_client.py
â”‚   â”œâ”€â”€ transform/              # MÃ³dulo de transformaciÃ³n
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ air_quality_transform.py
â”‚   â”œâ”€â”€ training/               # (prÃ³ximamente)
â”‚   â”œâ”€â”€ inference/              # (prÃ³ximamente)
â”‚   â””â”€â”€ monitoring/             # (prÃ³ximamente)
â”‚
â”œâ”€â”€ data/                       # Datos (gitignore excepto .gitkeep)
â”‚   â”œâ”€â”€ raw/                    # JSON crudos de la API
â”‚   â”‚   â””â”€â”€ Buenos_Aires/
â”‚   â”œâ”€â”€ stg/                    # Staging (no usado actualmente)
â”‚   â””â”€â”€ curated/                # Parquet procesados
â”‚       â””â”€â”€ Buenos_Aires_air_quality.parquet/
â”‚
â”œâ”€â”€ mlflow/                     # Artefactos de MLflow (prÃ³ximamente)
â”œâ”€â”€ notebooks/                  # Jupyter notebooks de exploraciÃ³n
â”œâ”€â”€ .github/workflows/          # GitHub Actions (prÃ³ximamente)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .gitattributes
â””â”€â”€ README.md                   # Este archivo
```

## ğŸš€ Inicio RÃ¡pido

### Requisitos Previos

- Docker Desktop instalado y corriendo
- ~6GB de espacio en disco para imÃ¡genes Docker
- Puerto 8080 disponible

### 1. Clonar el Repositorio

```bash
git clone <tu-repo>
cd air-quality-mlops
```

### 2. Levantar Airflow

```bash
cd airflow

# Construir imagen custom con Java + PySpark (~5 min primera vez)
docker compose build

# Levantar servicios (~1 min)
docker compose up -d

# Verificar que todo estÃ¡ corriendo
docker compose ps
```

### 3. Acceder a la UI

- **URL**: http://localhost:8080
- **Usuario**: `airflow`
- **Password**: `airflow`

### 4. Ejecutar el Pipeline

1. En la UI, activa el DAG `ingest_air_quality` (toggle ON)
2. Click en "Trigger DAG" (â–¶ï¸) para ejecutar la ingesta
3. Espera a que termine (tarea verde = Ã©xito)
4. Activa y ejecuta `transform_air_quality`
5. Verifica los datos generados:
   ```bash
   ls data/raw/Buenos_Aires/          # JSONs crudos
   ls data/curated/                   # Parquet procesado
   ```

### 5. Detener y Limpiar

```bash
# Detener servicios (preserva datos)
docker compose down

# Eliminar todo (incluye volÃºmenes de BD)
docker compose down -v

# Eliminar imÃ¡genes (libera ~6GB)
docker rmi airflow-custom:2.10.1-pyspark apache/airflow:2.10.1-python3.11 postgres:15 redis:7
```

## ğŸ“Š Datos

### Fuente de Datos

**Open-Meteo Air Quality API** (gratuita, sin API key)
- https://open-meteo.com/en/docs/air-quality-api

### Variables Capturadas (por hora)

| Variable | Unidad | DescripciÃ³n |
|----------|--------|-------------|
| `pm2_5` | Î¼g/mÂ³ | PartÃ­culas < 2.5 micras |
| `pm10` | Î¼g/mÂ³ | PartÃ­culas < 10 micras |
| `carbon_monoxide` | Î¼g/mÂ³ | MonÃ³xido de carbono |
| `nitrogen_dioxide` | Î¼g/mÂ³ | DiÃ³xido de nitrÃ³geno |
| `sulphur_dioxide` | Î¼g/mÂ³ | DiÃ³xido de azufre |
| `ozone` | Î¼g/mÂ³ | Ozono |
| `us_aqi` | Ã­ndice | US Air Quality Index |
| `european_aqi` | Ã­ndice | European AQI |

### ClasificaciÃ³n de Calidad del Aire

Basada en EPA AQI para PM2.5:

| Etiqueta | PM2.5 (Î¼g/mÂ³) | DescripciÃ³n |
|----------|---------------|-------------|
| `good` | < 12 | Buena calidad |
| `moderate` | 12 - 35.4 | Calidad moderada |
| `unhealthy` | â‰¥ 35.4 | No saludable |

### Cobertura Temporal

- **Granularidad**: Horaria (1 registro por hora)
- **HistÃ³rico**: 7 dÃ­as hacia atrÃ¡s
- **Forecast**: 1 dÃ­a hacia adelante
- **Ciudad**: Buenos Aires, Argentina (-34.6, -58.4)

## ğŸ”„ Pipeline de Datos

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Open-Meteo    â”‚â”€â”€â”€â”€â–¶â”‚   data/raw/     â”‚â”€â”€â”€â”€â–¶â”‚  data/curated/  â”‚
â”‚      API        â”‚     â”‚   *.json        â”‚     â”‚   *.parquet     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                       â”‚                       â”‚
   Ingesta DAG            JSON crudo              PySpark ETL
   (@hourly)              con arrays             DataFrame tabular
                          anidados               + clasificaciÃ³n
```

### DAG de Ingesta (`ingest_air_quality`)

- **Schedule**: `@hourly`
- **AcciÃ³n**: Llama a Open-Meteo API â†’ guarda JSON en `data/raw/{city}/`
- **Dependencias**: `requests` (incluido en Airflow)

### DAG de TransformaciÃ³n (`transform_air_quality`)

- **Schedule**: Cada 6 horas (`0 */6 * * *`)
- **AcciÃ³n**: Lee JSONs â†’ aplana con PySpark â†’ clasifica â†’ guarda Parquet
- **Dependencias**: PySpark + Java (incluidos en imagen custom)

## ğŸ³ Arquitectura Docker

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Docker Compose                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  Webserver  â”‚  â”‚  Scheduler  â”‚  â”‚   Worker    â”‚          â”‚
â”‚  â”‚   :8080     â”‚  â”‚             â”‚  â”‚  (Celery)   â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚         â”‚                â”‚                â”‚                  â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                          â”‚                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  PostgreSQL â”‚  â”‚    Redis    â”‚  â”‚  Triggerer  â”‚          â”‚
â”‚  â”‚  (metadata) â”‚  â”‚  (broker)   â”‚  â”‚             â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  VolÃºmenes montados:                                         â”‚
â”‚  - ./dags â†’ /opt/airflow/dags                               â”‚
â”‚  - ./logs â†’ /opt/airflow/logs                               â”‚
â”‚  - ../src â†’ /opt/airflow/src                                â”‚
â”‚  - ../data â†’ /opt/airflow/data                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ PrÃ³ximos Pasos

- [ ] **Entrenamiento**: Implementar pipeline con PyCaret + Optuna
- [ ] **MLflow**: Tracking de experimentos y registro de modelos
- [ ] **FastAPI**: API de inferencia con el mejor modelo
- [ ] **Evidently**: Monitoreo de data drift
- [ ] **GitHub Actions**: CI/CD para despliegue automatizado

## ğŸ‘¤ Autor

Proyecto desarrollado por Paul Lijtmaer como trabajo final de posgrado en MLOps.

## ğŸ“„ Licencia

Este proyecto es de uso acadÃ©mico.

