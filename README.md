# ğŸŒ¬ï¸ Air Quality MLOps

Proyecto de MLOps end-to-end para clasificaciÃ³n de calidad del aire, desarrollado como trabajo final de posgrado.

## ğŸ“‹ DescripciÃ³n

Pipeline completo de Machine Learning Operations que:

> ğŸ“Š **Ver [Diagrama de Arquitectura Completo](docs/architecture.md)** con Mermaid
1. **Ingesta** datos de calidad del aire desde Open-Meteo API (Airflow)
2. **Transforma** los datos crudos usando PySpark
3. **Versiona** datos con DVC + DagsHub
4. **Gestiona features** con Feast Feature Store
5. **Entrena** modelos con PyCaret + Optuna + MLflow
6. **Sirve** predicciones via FastAPI
7. **Monitorea** data drift con Evidently

## ğŸ› ï¸ Stack TecnolÃ³gico

| Componente | TecnologÃ­a | Estado |
|------------|------------|--------|
| OrquestaciÃ³n | Apache Airflow 2.10 | âœ… |
| Contenedores | Docker & Docker Compose | âœ… |
| TransformaciÃ³n | PySpark (local mode) | âœ… |
| Versionado de Datos | DVC + DagsHub | âœ… |
| Feature Store | Feast | âœ… |
| AutoML | PyCaret | âœ… |
| Hyperparameter Tuning | Optuna | âœ… |
| Experiment Tracking | MLflow (DagsHub) | âœ… |
| API | FastAPI | âœ… |
| Monitoreo | Evidently | âœ… |
| IaC | Terraform | âœ… |
| Kubernetes | Kind (local) | âœ… |
| CI/CD | GitHub Actions | âœ… |

## ğŸ“ Estructura del Proyecto

```
air-quality-mlops/
â”œâ”€â”€ airflow/                          # Apache Airflow
â”‚   â”œâ”€â”€ dags/                         # Definiciones de DAGs
â”‚   â”‚   â”œâ”€â”€ hello_airflow.py          # DAG de prueba
â”‚   â”‚   â”œâ”€â”€ ingest_air_quality.py     # Ingesta desde Open-Meteo
â”‚   â”‚   â””â”€â”€ transform_air_quality.py  # TransformaciÃ³n PySpark
â”‚   â”œâ”€â”€ docker-compose.yaml           # Servicios Docker
â”‚   â”œâ”€â”€ Dockerfile                    # Imagen custom (Java+PySpark)
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ src/                              # CÃ³digo fuente Python
â”‚   â”œâ”€â”€ ingestion/                    # MÃ³dulo de ingesta
â”‚   â”‚   â””â”€â”€ open_meteo_client.py      # Cliente Open-Meteo API
â”‚   â”œâ”€â”€ transform/                    # MÃ³dulo de transformaciÃ³n
â”‚   â”‚   â””â”€â”€ air_quality_transform.py  # Pipeline PySpark
â”‚   â”œâ”€â”€ training/                     # MÃ³dulo de entrenamiento
â”‚   â”‚   â””â”€â”€ train.py                  # PyCaret + Optuna + MLflow
â”‚   â”œâ”€â”€ inference/                    # API FastAPI
â”‚   â”‚   â”œâ”€â”€ main.py                   # Endpoints REST
â”‚   â”‚   â”œâ”€â”€ model.py                  # Carga del modelo
â”‚   â”‚   â””â”€â”€ schemas.py                # Schemas Pydantic
â”‚   â””â”€â”€ monitoring/                   # Monitoreo con Evidently
â”‚       â””â”€â”€ drift_detector.py         # DetecciÃ³n de data drift
â”‚
â”œâ”€â”€ feature_store/                    # Feast Feature Store
â”‚   â””â”€â”€ air_quality_features/
â”‚       â””â”€â”€ feature_repo/
â”‚           â”œâ”€â”€ air_quality_features.py  # DefiniciÃ³n de features
â”‚           â””â”€â”€ feature_store.yaml       # ConfiguraciÃ³n
â”‚
â”œâ”€â”€ data/                             # Datos (versionados con DVC)
â”‚   â”œâ”€â”€ raw/                          # JSON crudos de la API
â”‚   â””â”€â”€ curated/                      # Parquet procesados
â”‚
â”œâ”€â”€ models/                           # Modelos entrenados
â”‚   â””â”€â”€ air_quality_*_tuned.pkl       # Modelo PyCaret
â”‚
â”œâ”€â”€ reports/                          # Reportes generados
â”‚   â””â”€â”€ monitoring/                   # Reportes de Evidently (HTML)
â”‚
â”œâ”€â”€ infrastructure/                   # Infraestructura como cÃ³digo
â”‚   â”œâ”€â”€ terraform/                    # Archivos Terraform
â”‚   â”‚   â”œâ”€â”€ main.tf                   # Recursos principales
â”‚   â”‚   â”œâ”€â”€ variables.tf              # Variables
â”‚   â”‚   â””â”€â”€ outputs.tf                # Outputs
â”‚   â””â”€â”€ k8s/                          # Manifiestos Kubernetes
â”‚       â”œâ”€â”€ deployment.yaml           # Deployment de la API
â”‚       â””â”€â”€ service.yaml              # Service NodePort
â”‚
â”œâ”€â”€ docs/                             # DocumentaciÃ³n
â”‚   â””â”€â”€ architecture.md               # Diagramas de arquitectura
â”‚
â”œâ”€â”€ .github/workflows/                # CI/CD Pipelines
â”‚   â”œâ”€â”€ ci.yaml                       # Lint, tests, build
â”‚   â”œâ”€â”€ cd.yaml                       # Build y push imagen
â”‚   â””â”€â”€ model-training.yaml           # Training automÃ¡tico
â”‚
â”œâ”€â”€ .dvc/                             # ConfiguraciÃ³n DVC
â”œâ”€â”€ Dockerfile                        # Imagen Docker de la API
â”œâ”€â”€ docker-compose.yaml               # OrquestaciÃ³n Docker
â””â”€â”€ README.md
```

## ğŸš€ Inicio RÃ¡pido

### Requisitos Previos

- Python 3.11+
- Docker Desktop
- Git
- ~6GB de espacio en disco

### InstalaciÃ³n por Sistema Operativo

<details>
<summary>ğŸ <b>macOS</b></summary>

```bash
# Instalar Homebrew (si no lo tienes)
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Instalar dependencias
brew install python@3.11 uv git
brew install --cask docker

# Para Kubernetes (opcional)
brew install kind terraform kubectl
```
</details>

<details>
<summary>ğŸªŸ <b>Windows</b></summary>

```powershell
# Instalar Chocolatey (ejecutar PowerShell como Admin)
Set-ExecutionPolicy Bypass -Scope Process -Force
[System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072
iex ((New-Object System.Net.WebClient).DownloadString('https://community.chocolatey.org/install.ps1'))

# Reiniciar PowerShell y luego instalar
choco install python311 git docker-desktop -y

# Para Kubernetes (opcional)
choco install kind terraform kubernetes-cli -y

# Habilitar scripts en PowerShell
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser -Force
```
</details>

<details>
<summary>ğŸ§ <b>Linux (Ubuntu/Debian)</b></summary>

```bash
# Actualizar e instalar Python
sudo apt update
sudo apt install python3.11 python3.11-venv git curl -y

# Instalar Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo usermod -aG docker $USER

# Para Kubernetes (opcional)
# Kind
curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.20.0/kind-linux-amd64
chmod +x ./kind
sudo mv ./kind /usr/local/bin/kind

# Terraform
wget -O- https://apt.releases.hashicorp.com/gpg | sudo gpg --dearmor -o /usr/share/keyrings/hashicorp-archive-keyring.gpg
echo "deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main" | sudo tee /etc/apt/sources.list.d/hashicorp.list
sudo apt update && sudo apt install terraform kubectl -y
```
</details>

### 1. Clonar y Configurar Entorno

```bash
git clone https://github.com/plijtmaer/air-quality-mlops.git
cd air-quality-mlops
```

**Crear virtual environment:**

```bash
# macOS / Linux
python3.11 -m venv .venv
source .venv/bin/activate

# Windows PowerShell
python -m venv .venv
.\.venv\Scripts\Activate.ps1

# Windows Git Bash
python -m venv .venv
source .venv/Scripts/activate
```

**Instalar dependencias:**

```bash
# OpciÃ³n 1: Con uv (mÃ¡s rÃ¡pido)
pip install uv
uv pip install dvc dagshub mlflow feast pycaret optuna fastapi uvicorn evidently

# OpciÃ³n 2: Con pip tradicional
pip install dvc dagshub mlflow feast pycaret optuna fastapi uvicorn evidently
```

### 2. Descargar Datos (DVC)

```bash
# Configurar credenciales DVC (solo primera vez)
dvc remote modify origin --local auth basic
dvc remote modify origin --local user TU_USUARIO_DAGSHUB
dvc remote modify origin --local password TU_TOKEN_DAGSHUB

# Descargar datos
dvc pull
```

### 3. Ejecutar Training

```bash
python -m src.training.train

# Con parÃ¡metros personalizados
python -m src.training.train --metric F1 --min-f1 0.7 --tune-trials 30
```

### 4. Levantar Airflow (opcional)

```bash
cd airflow
docker compose build
docker compose up -d
# UI: http://localhost:8080 (airflow/airflow)
```

## ğŸ“Š Pipeline de Datos

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Open-Meteo    â”‚â”€â”€â”€â”€â–¶â”‚   data/raw/     â”‚â”€â”€â”€â”€â–¶â”‚  data/curated/  â”‚
â”‚      API        â”‚     â”‚   *.json        â”‚     â”‚   *.parquet     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                       â”‚                       â”‚
   Airflow DAG             DVC tracked            PySpark ETL
   (@hourly)                                    + clasificaciÃ³n
```

## ğŸ¤– Pipeline de Training

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  data/curated/  â”‚â”€â”€â”€â”€â–¶â”‚     PyCaret     â”‚â”€â”€â”€â”€â–¶â”‚     Optuna      â”‚
â”‚   *.parquet     â”‚     â”‚ compare_models  â”‚     â”‚   tune_model    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚                       â”‚
                          logs mÃ©tricas           Tuned Model
                               â”‚                       â”‚
                               â–¼                       â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚     MLflow      â”‚â—€â”€â”€â”€â”€â”‚     models/     â”‚
                        â”‚    (DagsHub)    â”‚     â”‚   *.pkl         â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Flujo detallado:**
1. **PyCaret** compara ~15 modelos â†’ selecciona el mejor por F1
2. **Optuna** tunea hiperparÃ¡metros del mejor modelo (20 trials)
3. **Modelo final** se exporta como `.pkl` y se loguea en MLflow

### Resultados del Ãšltimo Training

| MÃ©trica | Valor |
|---------|-------|
| **Mejor modelo** | Decision Tree Classifier |
| **F1 Score** | 0.9886 (98.86%) |
| **AUC** | 0.95 (95%) |
| **Accuracy** | 0.9923 (99.23%) |

Ver experimentos: https://dagshub.com/plijtmaer/air-quality-mlops.mlflow

## ğŸ½ï¸ Feast Feature Store

Features definidas para calidad del aire:

| Feature | Tipo | DescripciÃ³n |
|---------|------|-------------|
| `pm2_5` | Float | PM2.5 (Î¼g/mÂ³) |
| `pm10` | Float | PM10 (Î¼g/mÂ³) |
| `carbon_monoxide` | Float | CO (Î¼g/mÂ³) |
| `nitrogen_dioxide` | Float | NO2 (Î¼g/mÂ³) |
| `sulphur_dioxide` | Float | SO2 (Î¼g/mÂ³) |
| `ozone` | Float | O3 (Î¼g/mÂ³) |
| `us_aqi` | Int | US Air Quality Index |
| `european_aqi` | Int | European AQI |
| `air_quality_label` | String | good/moderate/unhealthy |

### Usar Feast

```bash
cd feature_store/air_quality_features/feature_repo

# Aplicar definiciones
feast apply

# Materializar features
feast materialize-incremental $(date -u +"%Y-%m-%dT%H:%M:%S")
```

## ğŸš€ FastAPI Inference API

API REST para predicciÃ³n de calidad del aire.

### Iniciar el Servidor

```bash
# Activar entorno virtual
source .venv/bin/activate  # Mac/Linux
.venv\Scripts\activate     # Windows

# Iniciar servidor
uvicorn src.inference.main:app --host 0.0.0.0 --port 8000

# O con recarga automÃ¡tica (desarrollo)
uvicorn src.inference.main:app --reload --port 8000
```

### Endpoints Disponibles

| Endpoint | MÃ©todo | DescripciÃ³n |
|----------|--------|-------------|
| `/` | GET | Info de la API |
| `/health` | GET | Health check |
| `/predict` | POST | PredicciÃ³n individual |
| `/predict/batch` | POST | PredicciÃ³n en lote |
| `/model/info` | GET | Info del modelo |
| `/docs` | GET | Swagger UI |
| `/redoc` | GET | ReDoc |

### Ejemplo de PredicciÃ³n

```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "pm2_5": 15.5,
    "pm10": 25.0,
    "carbon_monoxide": 200.0,
    "nitrogen_dioxide": 10.5,
    "sulphur_dioxide": 5.0,
    "ozone": 50.0,
    "us_aqi": 42,
    "european_aqi": 35
  }'
```

**Respuesta:**
```json
{
  "prediction": "moderate",
  "confidence": 1.0,
  "probabilities": null
}
```

## ğŸ“ˆ ClasificaciÃ³n de Calidad del Aire

Basada en EPA AQI para PM2.5:

| Etiqueta | PM2.5 (Î¼g/mÂ³) | DescripciÃ³n |
|----------|---------------|-------------|
| `good` | < 12 | Buena calidad |
| `moderate` | 12 - 35.4 | Calidad moderada |
| `unhealthy` | â‰¥ 35.4 | No saludable |

## ğŸ”— Enlaces

- **DagsHub Repo**: https://dagshub.com/plijtmaer/air-quality-mlops
- **MLflow Experiments**: https://dagshub.com/plijtmaer/air-quality-mlops.mlflow
- **Open-Meteo API**: https://open-meteo.com/en/docs/air-quality-api

## ğŸ“Š Monitoreo con Evidently

DetecciÃ³n de data drift comparando datos de producciÃ³n con datos de entrenamiento.

### Endpoints de Monitoreo

| Endpoint | MÃ©todo | DescripciÃ³n |
|----------|--------|-------------|
| `/monitoring/drift` | POST | Detectar drift en datos |
| `/monitoring/reference-stats` | GET | EstadÃ­sticas de referencia |
| `/monitoring/report` | POST | Generar reporte HTML |

### Ejemplo de DetecciÃ³n de Drift

```bash
curl -X POST "http://localhost:8000/monitoring/drift" \
  -H "Content-Type: application/json" \
  -d '{
    "samples": [
      {"pm2_5": 15.5, "pm10": 25.0, "carbon_monoxide": 200.0, "nitrogen_dioxide": 10.5, "sulphur_dioxide": 5.0, "ozone": 50.0, "us_aqi": 42, "european_aqi": 35},
      {"pm2_5": 18.0, "pm10": 30.0, "carbon_monoxide": 250.0, "nitrogen_dioxide": 12.0, "sulphur_dioxide": 6.0, "ozone": 55.0, "us_aqi": 50, "european_aqi": 40}
    ]
  }'
```

**Respuesta:**
```json
{
  "timestamp": "2025-12-05T...",
  "drift_detected": false,
  "drift_score": 0.0,
  "drifted_features": [],
  "feature_details": {...}
}
```

### Reportes HTML

Los reportes se guardan en `reports/monitoring/` como archivos HTML interactivos con:
- ğŸ“Š DistribuciÃ³n de cada feature (referencia vs actual)
- ğŸ“ˆ Tests estadÃ­sticos de drift por variable
- ğŸ¨ GrÃ¡ficos interactivos con Plotly

```bash
# Generar reporte via API
curl -X POST "http://localhost:8000/monitoring/report" \
  -H "Content-Type: application/json" \
  -d '{"samples": [{"pm2_5": 15, "pm10": 25, ...}]}'

# El reporte se guarda en: reports/monitoring/drift_report_YYYYMMDD_HHMMSS.html
```

## ğŸ³ Docker

La API estÃ¡ completamente Dockerizada.

### Comandos Docker

```bash
# Construir imagen
docker compose build

# Levantar servicios
docker compose up -d

# Ver logs
docker compose logs -f api

# Detener servicios
docker compose down

# Ver estado
docker compose ps
```

### Acceso

- **API**: http://localhost:8000
- **Swagger UI**: http://localhost:8000/docs
- **Health Check**: http://localhost:8000/health

## â˜¸ï¸ Kubernetes (Kind + Terraform)

Infraestructura como cÃ³digo para desplegar en Kubernetes local.

### Instalar Kind y Terraform

<details>
<summary>ğŸ <b>macOS</b></summary>

```bash
brew install kind terraform kubectl
```
</details>

<details>
<summary>ğŸªŸ <b>Windows</b> (PowerShell como Admin)</summary>

```powershell
# Con Chocolatey
choco install kind terraform kubernetes-cli -y

# O descargar manualmente:
# Kind: https://kind.sigs.k8s.io/dl/v0.20.0/kind-windows-amd64
# Terraform: https://releases.hashicorp.com/terraform/
```
</details>

<details>
<summary>ğŸ§ <b>Linux</b></summary>

```bash
# Kind
curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.20.0/kind-linux-amd64
chmod +x ./kind && sudo mv ./kind /usr/local/bin/kind

# Terraform
sudo apt install terraform
```
</details>

### Verificar InstalaciÃ³n

```bash
kind version      # DeberÃ­a mostrar v0.20.0 o superior
terraform version # DeberÃ­a mostrar v1.x.x
kubectl version   # Cliente de Kubernetes
```

### Despliegue con Terraform

```bash
cd infrastructure/terraform
terraform init    # Inicializar providers
terraform plan    # Ver quÃ© se va a crear
terraform apply   # Crear cluster y deploy (confirmar con 'yes')
```

### Acceso

- **API**: http://localhost:8080
- **Swagger UI**: http://localhost:8080/docs

### Comandos Ãºtiles

```bash
# Ver pods
kubectl get pods -n air-quality

# Ver logs
kubectl logs -f deployment/air-quality-api -n air-quality

# Escalar rÃ©plicas
kubectl scale deployment air-quality-api --replicas=3 -n air-quality

# Destruir todo
terraform destroy
```

Ver mÃ¡s detalles en [`infrastructure/README.md`](infrastructure/README.md).

## ğŸ”„ CI/CD con GitHub Actions

El proyecto incluye 3 workflows automatizados:

### Workflows

| Workflow | Trigger | DescripciÃ³n |
|----------|---------|-------------|
| **CI Pipeline** | Push/PR a main | Lint, tests, security scan, Docker build |
| **CD Pipeline** | Tags `v*.*.*` | Build y push a GitHub Container Registry |
| **Model Training** | Manual/Push a training | Entrena modelo y sube a MLflow |

### CI Pipeline (ci.yaml)
- âœ… Linting con Ruff
- âœ… Formato con Black
- âœ… Imports con isort
- âœ… Security scan con Bandit
- âœ… Docker build test

### CD Pipeline (cd.yaml)
- ğŸ³ Build multi-arquitectura (amd64, arm64)
- ğŸ“¦ Push a GitHub Container Registry
- ğŸ·ï¸ Tags semÃ¡nticos automÃ¡ticos

### Model Training (model-training.yaml)
- ğŸ¤– Ejecuta pipeline de training
- ğŸ“Š Logs a MLflow/DagsHub
- ğŸ’¾ Guarda modelo como artifact

### Secrets necesarios

Configura en GitHub â†’ Settings â†’ Secrets:

```
MLFLOW_TRACKING_URI=https://dagshub.com/plijtmaer/air-quality-mlops.mlflow
DAGSHUB_USER_TOKEN=<tu-token>
```

## ğŸ“ Estado del Proyecto

- [x] ~~**FastAPI**: API REST para inferencia~~
- [x] ~~**Evidently**: Monitoreo de data drift~~
- [x] ~~**Docker**: Containerizar la aplicaciÃ³n completa~~
- [x] ~~**Terraform**: Infraestructura como cÃ³digo~~
- [x] ~~**Kind**: Deployment en Kubernetes local~~
- [x] ~~**GitHub Actions**: CI/CD~~

## ğŸ› ï¸ Comandos Ãštiles

```bash
# Training
python -m src.training.train

# FastAPI
uvicorn src.inference.main:app --port 8000

# DVC
dvc pull                    # Descargar datos
dvc push                    # Subir datos
dvc status                  # Ver estado

# Feast
cd feature_store/air_quality_features/feature_repo
feast apply                 # Aplicar cambios
feast materialize-incremental "2025-12-05T00:00:00"

# Airflow
cd airflow
docker compose up -d        # Levantar
docker compose down         # Detener
docker compose logs -f      # Ver logs
```

## ğŸ‘¤ Autor

Proyecto desarrollado por **Paul Lijtmaer** como trabajo final de posgrado en MLOps.

## ğŸ“„ Licencia

Este proyecto es de uso acadÃ©mico.
